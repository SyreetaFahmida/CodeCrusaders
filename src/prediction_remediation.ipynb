{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ac7a0f-b1d8-4672-a256-e9f90ff4ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d4dc90-af1f-4843-823b-5b8c472da5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  vm_id            timestamp  cpu_usage  \\\n",
      "0  c5215826-6237-4a33-9312-72c1df909881  2023-01-25 09:10:54  54.881350   \n",
      "1  29690bc6-1f34-403b-b509-a1ecb1834fb8  2023-01-26 04:46:34  71.518937   \n",
      "2  2e55abc3-5bad-46cb-b445-a577f5e9bf2a  2023-01-13 23:39:47        NaN   \n",
      "3  e672e32f-c134-4fbc-992b-34eb63bef6bf  2023-02-09 11:45:49  54.488318   \n",
      "4  f38b8b50-6926-4533-be4f-89ad11624071  2023-06-14 08:27:26  42.365480   \n",
      "\n",
      "   memory_usage  network_traffic  power_consumption  \\\n",
      "0     78.950861       164.775973         287.808986   \n",
      "1     29.901883              NaN         362.273569   \n",
      "2     92.709195       203.674847         231.467903   \n",
      "3     88.100960              NaN         195.639954   \n",
      "4           NaN              NaN         359.451537   \n",
      "\n",
      "   num_executed_instructions  execution_time  energy_efficiency task_type  \\\n",
      "0                     7527.0       69.345575           0.553589   network   \n",
      "1                     5348.0       41.396040           0.349856        io   \n",
      "2                     5483.0       24.602549           0.796277        io   \n",
      "3                     5876.0       16.456670           0.529511   compute   \n",
      "4                     3361.0       55.307992           0.351907       NaN   \n",
      "\n",
      "  task_priority task_status  \n",
      "0        medium     waiting  \n",
      "1          high   completed  \n",
      "2        medium   completed  \n",
      "3          high   completed  \n",
      "4        medium     waiting  \n"
     ]
    }
   ],
   "source": [
    "    df=pd.read_csv(\"C:/downloads/CCPerformance/vmCloud_data.csv\", parse_dates=True)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f2adf76-61ec-46d0-a442-f337ecb51179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Function to convert string to datetime\n",
    "def convert(date_time):\n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    datetime_str = datetime.datetime.strptime(date_time, format)\n",
    "\n",
    "    return datetime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d807f75-d076-4aea-be23-c24b1e91ce55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VM  is doing good **\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fahmi\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahmi\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahmi\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahmi\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahmi\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahmi\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahmi\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahmi\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahmi\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\fahmi\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'remediaton' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVM  is doing good **\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mremediaton\u001b[49m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mremediation required:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# prob0=clf.predict_proba(test)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'remediaton' is not defined"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "    \n",
    "date_time = '2023-07-20 12:04:18'\n",
    "# print(convert(date_time))\n",
    "# print(type(convert(date_time)))\n",
    "cur_time=convert(date_time)\n",
    "#replacing with 2023 data for testing\n",
    "# print('date_time: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "\n",
    "df['timestamp']=pd.to_datetime(df['timestamp'])\n",
    "\n",
    "\n",
    "\n",
    "vms=df[\"vm_id\"].unique()\n",
    "# print(f\"Number of VMs: {len(vms)}\")\n",
    "# print(vms)\n",
    "# print(type(vms))\n",
    "\n",
    "\n",
    "# rec_df=df[df['timestamp']<=cur_time and df['timestamp']>=cur_time - timedelta(hours = 1)] #1 hoour for smoothing value calculation\n",
    "mask=(df['timestamp']<=cur_time)  & (df['timestamp']>=cur_time - timedelta(days = 30)) #1 hoour for smoothing value calculation\n",
    "rec_df=df.loc[mask]\n",
    "# print(rec_df)\n",
    "# print(rec_df.shape[0])\n",
    "span=10\n",
    "\n",
    "# Not enough log entries for prediction at VM level hence doing it at aggregate level\n",
    "#aggregate level\n",
    "df_vm=rec_df\n",
    "df_vm.set_index(\"timestamp\", inplace=True)\n",
    "# print(df_vm.shape[0])\n",
    "#mem\n",
    "mem=df_vm[\"memory_usage\"].to_frame()\n",
    "mem_usage=mem[\"memory_usage\"].ewm(span=span).mean()\n",
    "\n",
    "#network_io\n",
    "net=df_vm[df_vm['task_type']=='network']\n",
    "net=net[\"network_traffic\"].to_frame()\n",
    "net_usage=net[\"network_traffic\"].ewm(span=span).mean()\n",
    "\n",
    "#local_io\n",
    "io=df_vm[df_vm['task_type']=='io']\n",
    "io=io[\"execution_time\"].to_frame()\n",
    "io_usage=io[\"execution_time\"].ewm(span=span).mean()\n",
    "\n",
    "\n",
    "#nfs_io\n",
    "nfs=df_vm[df_vm['task_type']=='network']\n",
    "nfs=nfs[\"execution_time\"].to_frame()\n",
    "nfs_usage=nfs[\"execution_time\"].ewm(span=span).mean()\n",
    "\n",
    "# print(type(mem_usage))\n",
    "\n",
    "ins=np.array([mem_usage.iloc[0], net_usage.iloc[0], io_usage.iloc[0], nfs_usage.iloc[0]])\n",
    "test=ins\n",
    "\n",
    "clf = pickle.load(open(\"../models/stacking\", 'rb')) \n",
    "final_model = pickle.load(open(\"../models/voting\", 'rb')) \n",
    "\n",
    "# print(test)\n",
    "# print(test.shape)\n",
    "\n",
    "remediation=0\n",
    "if clf.predict([test]) == 1: # and clf.predict_proba() >=0.5:\n",
    "    print(f\"VM  is going to fail soon **\\n\")\n",
    "    remediation=1\n",
    "    \n",
    "elif  final_model.predict([test]) == 1:# and final_model.predict_proba() >=0.5:\n",
    "    print(f\"VM  is going to fail soon **\\n\")\n",
    "    remediation=1\n",
    "else:\n",
    "    print(f\"VM  is doing good **\\n\")\n",
    "\n",
    "if remediaton:\n",
    "    print(\"remediation required:\\n\")\n",
    "    # prob0=clf.predict_proba(test)\n",
    "    cause=-1\n",
    "    causes=list(\"mem_usage\", \"net_usage\", \"io_usage\", \"nfs_usage\")\n",
    "    for i, c  in enumerate(causes):\n",
    "        print(i)\n",
    "        prob[i]=1\n",
    "    for i, c  in enumerate(causes):\n",
    "        ins[i]=0\n",
    "        if clf.predict(ins)==0:\n",
    "            cause=i\n",
    "            break\n",
    "        else:\n",
    "            prob[i]=clf.predict_proba(ins)\n",
    "\n",
    "        ins=test\n",
    "\n",
    "    if cause ==-1:\n",
    "        cause = np.where(prob == np.min(prob))[0]\n",
    "\n",
    "\n",
    "    match cause:\n",
    "        case '0': \n",
    "            print(\"Increase memory\\n\")\n",
    "            \n",
    "        case '1': \n",
    "            print(\"Increase network bandwidth\\n\")\n",
    "            \n",
    "        case '2': \n",
    "            print(\"Use VM of higher configuration\\n\")\n",
    "            \n",
    "        case '3': \n",
    "            print(\"Use better design/architecture to reduce nfs calls\\n\")\n",
    "            \n",
    "\n",
    "                               \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "                      \n",
    "# #VM level\n",
    "# for i, v in enumerate(vms):\n",
    "#     df_vm=rec_df[rec_df['vm_id']==v]\n",
    "#     print(df_vm.shape[0])    \n",
    "#     if df_vm.shape[0] <span:\n",
    "#         continue\n",
    "\n",
    "#     df_vm.set_index(\"timestamp\", inplace=True)\n",
    "#     print(df_vm.shape[0])\n",
    "#     #mem\n",
    "#     mem=df_vm[\"memory_usage\"].to_frame()\n",
    "#     mem_usage=mem[\"memory_usage\"].ewm(span=span).mean()\n",
    "\n",
    "#     #network_io\n",
    "#     net=df_vm[df_vm['task_type']=='network']\n",
    "#     net=net[\"network_traffic\"].to_frame()\n",
    "#     net_usage=net[\"network_traffic\"].ewm(span=span).mean()\n",
    "\n",
    "#     #local_io\n",
    "#     io=df_vm[df_vm['task_type']=='io']\n",
    "#     io=io[\"execution_time\"].to_frame()\n",
    "#     io_usage=io[\"execution_time\"].ewm(span=span).mean()\n",
    "\n",
    "\n",
    "#     #nfs_io\n",
    "#     nfs=df_vm[df_vm['task_type']=='network']\n",
    "#     nfs=nfs[\"execution_time\"].to_frame()\n",
    "#     nfs_usage=nfs[\"execution_time\"].ewm(span=span).mean()\n",
    "\n",
    "#     ins=[mem_usage.iloc[0], net_usage.iloc[0], io_usage.iloc[0], nfs_usage.iloc[0]]\n",
    "\n",
    "#     test=pd.DataFrame(ins, columns=['memory_GB',  'network_log10_MBps',  'local_IO_log10_MBps',  'NFS_IO_log10_MBps'])\n",
    "#     print(test)\n",
    "\n",
    "#     if clf.predict(test) == 1: # and clf.predict_proba() >=0.5:\n",
    "#         print(f\"VM {v} is going to fail soon **\\n\")\n",
    "#         continue\n",
    "        \n",
    "#     if final_model.predict(test) == 1:# and final_model.predict_proba() >=0.5:\n",
    "#         print(f\"VM {v} is going to fail soon **\\n\")\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"VM {v} is doing good **\\n\")\n",
    "    \n",
    "                \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2aa97-8e0d-4329-befe-11c98bc03e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
